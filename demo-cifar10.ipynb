{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":283795,"sourceType":"datasetVersion","datasetId":118250}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"22-09-2024, Ketan\n\nIMPORTS","metadata":{}},{"cell_type":"code","source":"!pip install tensorflow\n!pip install -qq -U diffusers datasets transformers accelerate==0.21.0 ftfy pyarrow==9.0.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CLONING THE REPO","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/KetanMann/Class_Conditioned_Diffusion_Training_Script-MULTI-GPU-/","metadata":{"execution":{"iopub.status.busy":"2024-09-21T20:34:07.671922Z","iopub.execute_input":"2024-09-21T20:34:07.672837Z","iopub.status.idle":"2024-09-21T20:34:09.555751Z","shell.execute_reply.started":"2024-09-21T20:34:07.672793Z","shell.execute_reply":"2024-09-21T20:34:09.554777Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Cloning into 'Class_Conditioned_Diffusion_Training_Script-MULTI-GPU-'...\nremote: Enumerating objects: 232, done.\u001b[K\nremote: Counting objects: 100% (98/98), done.\u001b[K\nremote: Compressing objects: 100% (93/93), done.\u001b[K\nremote: Total 232 (delta 60), reused 5 (delta 5), pack-reused 134 (from 1)\u001b[K\nReceiving objects: 100% (232/232), 11.09 MiB | 35.38 MiB/s, done.\nResolving deltas: 100% (132/132), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2024-09-21T20:31:42.013568Z","iopub.execute_input":"2024-09-21T20:31:42.013903Z","iopub.status.idle":"2024-09-21T20:31:42.998916Z","shell.execute_reply.started":"2024-09-21T20:31:42.013867Z","shell.execute_reply":"2024-09-21T20:31:42.997901Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[0m\u001b[01;34mClass_Conditioned_Diffusion_Training_Script-MULTI-GPU-\u001b[0m/\n","output_type":"stream"}]},{"cell_type":"code","source":"cd Class_Conditioned_Diffusion_Training_Script-MULTI-GPU-/","metadata":{"execution":{"iopub.status.busy":"2024-09-21T20:34:15.904866Z","iopub.execute_input":"2024-09-21T20:34:15.905284Z","iopub.status.idle":"2024-09-21T20:34:15.911911Z","shell.execute_reply.started":"2024-09-21T20:34:15.905243Z","shell.execute_reply":"2024-09-21T20:34:15.910977Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/kaggle/working/Class_Conditioned_Diffusion_Training_Script-MULTI-GPU-/Class_Conditioned_Diffusion_Training_Script-MULTI-GPU-\n","output_type":"stream"}]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2024-09-21T20:34:17.527065Z","iopub.execute_input":"2024-09-21T20:34:17.527436Z","iopub.status.idle":"2024-09-21T20:34:18.503114Z","shell.execute_reply.started":"2024-09-21T20:34:17.527401Z","shell.execute_reply":"2024-09-21T20:34:18.502172Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Algorithm.jpg                               grid_images.gif\nDemo_FER2013_and_CIFAR10_HuggingFace.ipynb  grid_images_fer.gif\nLICENSE                                     sampling.py\nREADME.md                                   train-conditional-tutorial.ipynb\nconditional_pipeline.py                     train_conditional.py\n","output_type":"stream"}]},{"cell_type":"markdown","source":"WANDB LOGIN(You can changer logger, for more information run: !python train_conditional.py --help","metadata":{}},{"cell_type":"code","source":"!python train_conditional.py --help","metadata":{"execution":{"iopub.status.busy":"2024-09-21T20:41:40.402348Z","iopub.execute_input":"2024-09-21T20:41:40.402708Z","iopub.status.idle":"2024-09-21T20:41:51.782964Z","shell.execute_reply.started":"2024-09-21T20:41:40.402676Z","shell.execute_reply":"2024-09-21T20:41:51.781990Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"usage: train_conditional.py [-h] [--dataset_name DATASET_NAME]\n                            [--dataset_config_name DATASET_CONFIG_NAME]\n                            [--model_config_name_or_path MODEL_CONFIG_NAME_OR_PATH]\n                            [--train_data_dir TRAIN_DATA_DIR]\n                            [--output_dir OUTPUT_DIR] [--overwrite_output_dir]\n                            [--cache_dir CACHE_DIR] [--resolution RESOLUTION]\n                            [--center_crop] [--random_flip]\n                            [--train_batch_size TRAIN_BATCH_SIZE]\n                            [--eval_batch_size EVAL_BATCH_SIZE]\n                            [--num_classes NUM_CLASSES]\n                            [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n                            [--num_epochs NUM_EPOCHS]\n                            [--save_images_epochs SAVE_IMAGES_EPOCHS]\n                            [--save_model_epochs SAVE_MODEL_EPOCHS]\n                            [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n                            [--learning_rate LEARNING_RATE]\n                            [--lr_scheduler LR_SCHEDULER]\n                            [--lr_warmup_steps LR_WARMUP_STEPS]\n                            [--adam_beta1 ADAM_BETA1]\n                            [--adam_beta2 ADAM_BETA2]\n                            [--adam_weight_decay ADAM_WEIGHT_DECAY]\n                            [--adam_epsilon ADAM_EPSILON] [--use_ema]\n                            [--ema_inv_gamma EMA_INV_GAMMA]\n                            [--ema_power EMA_POWER]\n                            [--ema_max_decay EMA_MAX_DECAY] [--push_to_hub]\n                            [--hub_token HUB_TOKEN]\n                            [--hub_model_id HUB_MODEL_ID] [--hub_private_repo]\n                            [--logger {tensorboard,wandb}]\n                            [--logging_dir LOGGING_DIR]\n                            [--local_rank LOCAL_RANK]\n                            [--mixed_precision {no,fp16,bf16}]\n                            [--prediction_type {epsilon,sample}]\n                            [--ddpm_num_steps DDPM_NUM_STEPS]\n                            [--ddpm_num_inference_steps DDPM_NUM_INFERENCE_STEPS]\n                            [--ddpm_beta_schedule DDPM_BETA_SCHEDULE]\n                            [--checkpointing_steps CHECKPOINTING_STEPS]\n                            [--checkpoints_total_limit CHECKPOINTS_TOTAL_LIMIT]\n                            [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n\nSimple example of a training script.\n\noptions:\n  -h, --help            show this help message and exit\n  --dataset_name DATASET_NAME\n                        The name of the Dataset (from the HuggingFace hub) to\n                        train on (could be your own, possibly private,\n                        dataset). It can also be a path pointing to a local\n                        copy of a dataset in your filesystem, or to a folder\n                        containing files that HF Datasets can understand.\n  --dataset_config_name DATASET_CONFIG_NAME\n                        The config of the Dataset, leave as None if there's\n                        only one config.\n  --model_config_name_or_path MODEL_CONFIG_NAME_OR_PATH\n                        The config of the UNet model to train, leave as None\n                        to use standard DDPM configuration.\n  --train_data_dir TRAIN_DATA_DIR\n                        A folder containing the training data. Folder contents\n                        must follow the structure described in https://hugging\n                        face.co/docs/datasets/image_dataset#imagefolder. In\n                        particular, a `metadata.jsonl` file must exist to\n                        provide the captions for the images. Ignored if\n                        `dataset_name` is specified.\n  --output_dir OUTPUT_DIR\n                        The output directory where the model predictions and\n                        checkpoints will be written.\n  --overwrite_output_dir\n  --cache_dir CACHE_DIR\n                        The directory where the downloaded models and datasets\n                        will be stored.\n  --resolution RESOLUTION\n                        The resolution for input images, all the images in the\n                        train/validation dataset will be resized to this\n                        resolution\n  --center_crop         Whether to center crop the input images to the\n                        resolution. If not set, the images will be randomly\n                        cropped. The images will be resized to the resolution\n                        first before cropping.\n  --random_flip         whether to randomly flip images horizontally\n  --train_batch_size TRAIN_BATCH_SIZE\n                        Batch size (per device) for the training dataloader.\n  --eval_batch_size EVAL_BATCH_SIZE\n                        The number of images to generate for evaluation.\n  --num_classes NUM_CLASSES\n                        The number of class labels\n  --dataloader_num_workers DATALOADER_NUM_WORKERS\n                        The number of subprocesses to use for data loading. 0\n                        means that the data will be loaded in the main\n                        process.\n  --num_epochs NUM_EPOCHS\n  --save_images_epochs SAVE_IMAGES_EPOCHS\n                        How often to save images during training.\n  --save_model_epochs SAVE_MODEL_EPOCHS\n                        How often to save the model during training.\n  --gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS\n                        Number of updates steps to accumulate before\n                        performing a backward/update pass.\n  --learning_rate LEARNING_RATE\n                        Initial learning rate (after the potential warmup\n                        period) to use.\n  --lr_scheduler LR_SCHEDULER\n                        The scheduler type to use. Choose between [\"linear\",\n                        \"cosine\", \"cosine_with_restarts\", \"polynomial\",\n                        \"constant\", \"constant_with_warmup\"]\n  --lr_warmup_steps LR_WARMUP_STEPS\n                        Number of steps for the warmup in the lr scheduler.\n  --adam_beta1 ADAM_BETA1\n                        The beta1 parameter for the Adam optimizer.\n  --adam_beta2 ADAM_BETA2\n                        The beta2 parameter for the Adam optimizer.\n  --adam_weight_decay ADAM_WEIGHT_DECAY\n                        Weight decay magnitude for the Adam optimizer.\n  --adam_epsilon ADAM_EPSILON\n                        Epsilon value for the Adam optimizer.\n  --use_ema             Whether to use Exponential Moving Average for the\n                        final model weights.\n  --ema_inv_gamma EMA_INV_GAMMA\n                        The inverse gamma value for the EMA decay.\n  --ema_power EMA_POWER\n                        The power value for the EMA decay.\n  --ema_max_decay EMA_MAX_DECAY\n                        The maximum decay magnitude for EMA.\n  --push_to_hub         Whether or not to push the model to the Hub.\n  --hub_token HUB_TOKEN\n                        The token to use to push to the Model Hub.\n  --hub_model_id HUB_MODEL_ID\n                        The name of the repository to keep in sync with the\n                        local `output_dir`.\n  --hub_private_repo    Whether or not to create a private repository.\n  --logger {tensorboard,wandb}\n                        Whether to use\n                        [tensorboard](https://www.tensorflow.org/tensorboard)\n                        or [wandb](https://www.wandb.ai) for experiment\n                        tracking and logging of model metrics and model\n                        checkpoints\n  --logging_dir LOGGING_DIR\n                        [TensorBoard](https://www.tensorflow.org/tensorboard)\n                        log directory. Will default to\n                        *output_dir/runs/**CURRENT_DATETIME_HOSTNAME***.\n  --local_rank LOCAL_RANK\n                        For distributed training: local_rank\n  --mixed_precision {no,fp16,bf16}\n                        Whether to use mixed precision. Choosebetween fp16 and\n                        bf16 (bfloat16). Bf16 requires PyTorch >= 1.10.and an\n                        Nvidia Ampere GPU.\n  --prediction_type {epsilon,sample}\n                        Whether the model should predict the 'epsilon'/noise\n                        error or directly the reconstructed image 'x0'.\n  --ddpm_num_steps DDPM_NUM_STEPS\n  --ddpm_num_inference_steps DDPM_NUM_INFERENCE_STEPS\n  --ddpm_beta_schedule DDPM_BETA_SCHEDULE\n  --checkpointing_steps CHECKPOINTING_STEPS\n                        Save a checkpoint of the training state every X\n                        updates. These checkpoints are only suitable for\n                        resuming training using `--resume_from_checkpoint`.\n  --checkpoints_total_limit CHECKPOINTS_TOTAL_LIMIT\n                        Max number of checkpoints to store.\n  --resume_from_checkpoint RESUME_FROM_CHECKPOINT\n                        Whether training should be resumed from a previous\n                        checkpoint. Use a path saved by\n                        `--checkpointing_steps`, or `\"latest\"` to\n                        automatically select the last available checkpoint.\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\nwandb.login()","metadata":{"execution":{"iopub.status.busy":"2024-09-21T20:32:12.110374Z","iopub.execute_input":"2024-09-21T20:32:12.110770Z","iopub.status.idle":"2024-09-21T20:32:20.452517Z","shell.execute_reply.started":"2024-09-21T20:32:12.110729Z","shell.execute_reply":"2024-09-21T20:32:20.451420Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"RUNNING THE SCRIPT","metadata":{}},{"cell_type":"code","source":"\n!accelerate launch --multi_gpu train_conditional.py \\\n  --dataset_name=\"/kaggle/input/cifar10-pngs-in-folders/cifar10/train\" \\\n  --resolution=512 \\\n  --output_dir={model_name} \\\n  --train_batch_size=1 \\\n  --dataloader_num_workers=8 \\\n  --eval_batch_size=1 \\\n  --num_epochs=2000 \\\n  --use_ema \\\n  --gradient_accumulation_steps=4 \\\n  --learning_rate=5e-5 \\\n  --lr_warmup_steps=1000 \\\n  --mixed_precision=\"no\" \\\n  --save_images_epoch=15 \\\n  --ddpm_beta_schedule=\"squaredcos_cap_v2\" \\\n  --checkpointing_steps=2000 \\\n  --resume_from_checkpoint=\"latest\" \\\n  --num_classes=10 \\\n  --prediction_type=\"sample\" \\\n  --logger=\"wandb\"  ","metadata":{"execution":{"iopub.status.busy":"2024-09-21T20:34:24.056580Z","iopub.execute_input":"2024-09-21T20:34:24.056996Z","iopub.status.idle":"2024-09-21T20:39:19.146535Z","shell.execute_reply.started":"2024-09-21T20:34:24.056953Z","shell.execute_reply":"2024-09-21T20:39:19.145273Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Resolving data files: 100%|███████████| 50000/50000 [00:00<00:00, 117804.49it/s]\nResolving data files: 100%|███████████| 50000/50000 [00:00<00:00, 130257.73it/s]\nComputing checksums: 100%|██████████████| 50000/50000 [00:06<00:00, 7529.09it/s]\nGenerating train split: 50000 examples [00:05, 9411.31 examples/s]\n/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mketanmann07\u001b[0m (\u001b[33mketanwork\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.18.1 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.7\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/Class_Conditioned_Diffusion_Training_Script-MULTI-GPU-/Class_Conditioned_Diffusion_Training_Script-MULTI-GPU-/wandb/run-20240921_203821-zqdgosee\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msparkling-salad-44\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ketanwork/train_conditional\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ketanwork/train_conditional/runs/zqdgosee\u001b[0m\nCheckpoint 'latest' does not exist. Starting a new training run.\nEpoch 0:   0%|                                         | 0/6250 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nEpoch 0:   0%| | 0/6250 [00:05<?, ?it/s, ema_decay=None, loss=0.151, lr=0, step=/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:768: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\ngrad.sizes() = [512, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]\nbucket_view.sizes() = [512, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at /usr/local/src/pytorch/torch/csrc/distributed/c10d/reducer.cpp:327.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:768: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\ngrad.sizes() = [512, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]\nbucket_view.sizes() = [512, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at /usr/local/src/pytorch/torch/csrc/distributed/c10d/reducer.cpp:327.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n/opt/conda/lib/python3.10/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n  warnings.warn(\nEpoch 0:   0%| | 7/6250 [00:39<9:15:40,  5.34s/it, ema_decay=0.768, loss=0.0777,^C\nW0921 20:39:18.421000 138655047038784 torch/distributed/elastic/agent/server/api.py:688] Received Signals.SIGINT death signal, shutting down workers\nW0921 20:39:18.422000 138655047038784 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 220 closing signal SIGINT\nW0921 20:39:18.422000 138655047038784 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 221 closing signal SIGINT\n","output_type":"stream"}]},{"cell_type":"markdown","source":"YOUR TASK\n\nSAMPLING AFTER TRAINING, PLEASE CHECK conditional_pipeline.py.\n\nHint: See training script has sampling after some epochs, try to apply same implementation.","metadata":{}},{"cell_type":"markdown","source":"More links:- \nhttps://huggingface.co/Ketansomewhere/cifar10_conditional_diffusion1\nhttps://huggingface.co/Ketansomewhere/FER_2013_Conditional_Diffusion","metadata":{}}]}